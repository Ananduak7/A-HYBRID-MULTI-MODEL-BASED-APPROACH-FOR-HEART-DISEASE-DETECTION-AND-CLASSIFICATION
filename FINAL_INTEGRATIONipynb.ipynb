{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11-no3oARWKu_urs7W8uc6X9erAl9MA_R",
      "authorship_tag": "ABX9TyPpDiUMpG/QFgAYTvKyS0fS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananduak7/A-HYBRID-MULTI-MODEL-BASED-APPROACH-FOR-HEART-DISEASE-DETECTION-AND-CLASSIFICATION/blob/main/FINAL_INTEGRATIONipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhR5K349Pq_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists(\"/content/e00055.wav\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htFxlguiySdN",
        "outputId": "57c8a88f-c299-4f2e-db73-5c98f879fe62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Risk Prioritization Logic:\n",
        "Audio Model (Heart Sound Analysis)\n",
        "\n",
        "Unhealthy (1.0 probability) â†’ High risk\n",
        "Healthy (1.0 probability) â†’ Low risk\n",
        "Borderline cases (0.4 - 0.6 probability) â†’ Medium risk\n",
        "ECG Model (Image Classification)\n",
        "\n",
        "Myocardial Infarction & History of Myocardial Infarction â†’ Highest risk\n",
        "Abnormal Heartbeat â†’ Medium risk\n",
        "Normal â†’ Low risk\n",
        "Both results are combined to generate a final risk score (0-100%) and risk category (Low/Medium/High/Severe)."
      ],
      "metadata": {
        "id": "cJ8vsegSQkrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# âœ… Load Audio Classification Model (BiLSTM)\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "audio_model = tf.keras.models.load_model(AUDIO_MODEL_PATH)\n",
        "\n",
        "# âœ… Load ECG Classification Model (EfficientNet + ResNet + MLP)\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "\n",
        "ecg_model = load_model(ECG_MODEL_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder for ECG Class Labels\n",
        "with open(ENCODER_PATH, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# âœ… Load Pre-trained Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Define Class Labels for ECG Model\n",
        "print(\"Available ECG Class Labels:\", label_encoder.classes_)\n",
        "\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "\n",
        "AUDIO_RISK_WEIGHTS = {\n",
        "    \"Healthy\": 0.1,\n",
        "    \"Unhealthy\": 0.9\n",
        "}\n",
        "\n",
        "# âœ… Function to Preprocess Audio File\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "\n",
        "        # Padding or truncating to ensure consistent input length\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        if pad_width > 0:\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_pad_len]\n",
        "\n",
        "        mfccs = mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "        return mfccs\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# âœ… Function to Predict Heart Condition from Audio\n",
        "def detect_heart_disease(file_path):\n",
        "    features = preprocess_audio(file_path)\n",
        "    if features is None:\n",
        "        print(\"Error in preprocessing the audio file.\")\n",
        "        return None, 0.0\n",
        "\n",
        "    prediction = audio_model.predict(features)\n",
        "    confidence = float(prediction[0])  # Probability of being Unhealthy\n",
        "    predicted_class = \"Unhealthy\" if confidence > 0.5 else \"Healthy\"\n",
        "    confidence = confidence if predicted_class == \"Unhealthy\" else 1 - confidence  # Adjust confidence\n",
        "\n",
        "    print(f\"ğŸ”Š Audio Prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# âœ… Function to Preprocess ECG Image\n",
        "def preprocess_image(image_path):\n",
        "    if not os.path.exists(image_path):\n",
        "        raise ValueError(f\"Error: File does not exist at {image_path}\")\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(\"Error: Unable to read the image. Check if the file format is supported.\")\n",
        "\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# âœ… Function to Predict Heart Condition from ECG Image\n",
        "def predict_disease(image_path):\n",
        "    img = preprocess_image(image_path)\n",
        "\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    confidence = float(np.max(prediction))\n",
        "\n",
        "    print(f\"ğŸ“Ÿ ECG Prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# âœ… Function to Compute Risk Score\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence):\n",
        "    if ecg_result not in ECG_RISK_WEIGHTS:\n",
        "        raise KeyError(f\"Unknown ECG class detected: {ecg_result}. Please check class labels.\")\n",
        "\n",
        "    # Compute risk values\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS[ecg_result] * ecg_confidence\n",
        "\n",
        "    final_risk_score = (audio_risk + ecg_risk) / 2  # Weighted average\n",
        "    print(f\"ğŸ©º Patient's Risk Score: {final_risk_score:.2f} (0 - Low, 1 - High)\")\n",
        "\n",
        "    # Interpret risk level\n",
        "    if final_risk_score >= 0.8:\n",
        "        print(\"âš ï¸ High Risk! Immediate medical attention recommended.\")\n",
        "    elif final_risk_score >= 0.5:\n",
        "        print(\"âš ï¸ Moderate Risk. Consult a cardiologist soon.\")\n",
        "    else:\n",
        "        print(\"âœ… Low Risk. Maintain a healthy lifestyle.\")\n",
        "\n",
        "    return final_risk_score\n",
        "\n",
        "# âœ… Main Function to Evaluate Patient's Health\n",
        "def evaluate_patient(audio_file_path, ecg_file_path):\n",
        "    print(\"\\nğŸ” Evaluating Patient's Heart Health...\\n\")\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_file_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_file_path)\n",
        "\n",
        "    if audio_result is None or ecg_result is None:\n",
        "        print(\"âŒ Error in processing patient data.\")\n",
        "        return\n",
        "\n",
        "    risk_score = calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence)\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "AUDIO_FILE_PATH = \"/content/f0108.wav\"\n",
        "ECG_IMAGE_PATH = \"/content/HB(3).jpg\"\n",
        "\n",
        "evaluate_patient(AUDIO_FILE_PATH, ECG_IMAGE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCQhrDaL0gj7",
        "outputId": "a95487dd-9d5e-472e-c183-567d4937d730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available ECG Class Labels: ['ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
            " 'ECG Images of Patient that have History of MI (172x12=2064)'\n",
            " 'ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
            " 'Normal Person ECG Images (284x12=3408)']\n",
            "\n",
            "ğŸ” Evaluating Patient's Heart Health...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c80b6ac6e80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-08497c3a9641>:71: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  confidence = float(prediction[0])  # Probability of being Unhealthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”Š Audio Prediction: Healthy (Confidence: 1.00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c80b6ac7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "ğŸ“Ÿ ECG Prediction: ECG Images of Patient that have abnormal heartbeat (233x12=2796) (Confidence: 0.94)\n",
            "ğŸ©º Patient's Risk Score: 0.33 (0 - Low, 1 - High)\n",
            "âœ… Low Risk. Maintain a healthy lifestyle.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3322629512133972"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rVHLQtQfRQfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print available class names\n",
        "print(\"Available ECG Class Labels:\", label_encoder.classes_)\n",
        "\n",
        "# Define a normalized risk weight dictionary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4IMUEksRQ_I",
        "outputId": "18b8fa52-fe11-4494-8a00-6ec94ac64fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available ECG Class Labels: ['ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
            " 'ECG Images of Patient that have History of MI (172x12=2064)'\n",
            " 'ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
            " 'Normal Person ECG Images (284x12=3408)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import logging\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# âœ… Set Up Logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# âœ… Load Audio Classification Model (BiLSTM)\n",
        "try:\n",
        "    AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "    audio_model = tf.keras.models.load_model(AUDIO_MODEL_PATH)\n",
        "    logging.info(\"Audio classification model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load audio model: {e}\")\n",
        "\n",
        "# âœ… Load ECG Classification Model (EfficientNet + ResNet + MLP)\n",
        "try:\n",
        "    ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "    ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "    ecg_model = load_model(ECG_MODEL_PATH)\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "    logging.info(\"ECG classification model and label encoder loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load ECG model or label encoder: {e}\")\n",
        "\n",
        "# âœ… Load Pre-trained Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Define Class Labels for ECG Model\n",
        "try:\n",
        "    print(\"Available ECG Class Labels:\", label_encoder.classes_)\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to read label encoder classes: {e}\")\n",
        "\n",
        "# âœ… Define Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "\n",
        "AUDIO_RISK_WEIGHTS = {\n",
        "    \"Healthy\": 0.1,\n",
        "    \"Unhealthy\": 0.9\n",
        "}\n",
        "\n",
        "# âœ… Function to Preprocess Audio File\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"Audio file not found: {file_path}\")\n",
        "\n",
        "        audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "\n",
        "        # Padding or truncating to ensure consistent input length\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        if pad_width > 0:\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_pad_len]\n",
        "\n",
        "        mfccs = mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "        return mfccs\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# âœ… Function to Predict Heart Condition from Audio\n",
        "def detect_heart_disease(file_path):\n",
        "    features = preprocess_audio(file_path)\n",
        "    if features is None:\n",
        "        logging.error(\"Error in preprocessing the audio file.\")\n",
        "        return None, 0.0\n",
        "\n",
        "    prediction = audio_model.predict(features)\n",
        "    confidence = float(prediction[0])  # Probability of being Unhealthy\n",
        "    predicted_class = \"Unhealthy\" if confidence > 0.5 else \"Healthy\"\n",
        "    confidence = confidence if predicted_class == \"Unhealthy\" else 1 - confidence  # Adjust confidence\n",
        "\n",
        "    logging.info(f\"ğŸ”Š Audio Prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# âœ… Function to Preprocess ECG Image\n",
        "def preprocess_image(image_path):\n",
        "    try:\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"ECG file not found: {image_path}\")\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(\"Unable to read the ECG image.\")\n",
        "\n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = preprocess_input(img)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing ECG image: {e}\")\n",
        "        return None\n",
        "\n",
        "# âœ… Function to Predict Heart Condition from ECG Image\n",
        "def predict_disease(image_path):\n",
        "    img = preprocess_image(image_path)\n",
        "    if img is None:\n",
        "        return None, 0.0\n",
        "\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    confidence = float(np.max(prediction))\n",
        "\n",
        "    logging.info(f\"ğŸ“Ÿ ECG Prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# âœ… Function to Compute Risk Score\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence):\n",
        "    if ecg_result not in ECG_RISK_WEIGHTS:\n",
        "        logging.error(f\"Unknown ECG class detected: {ecg_result}.\")\n",
        "        return None\n",
        "\n",
        "    # Compute risk values\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS[ecg_result] * ecg_confidence\n",
        "\n",
        "    final_risk_score = (audio_risk + ecg_risk) / 2  # Weighted average\n",
        "    logging.info(f\"ğŸ©º Patient's Risk Score: {final_risk_score:.2f} (0 - Low, 1 - High)\")\n",
        "\n",
        "    return final_risk_score\n",
        "\n",
        "# âœ… Main Function to Evaluate Patient's Health\n",
        "def evaluate_patient(audio_file_path, ecg_file_path):\n",
        "    logging.info(\"\\nğŸ” Evaluating Patient's Heart Health...\\n\")\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_file_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_file_path)\n",
        "\n",
        "    if audio_result is None or ecg_result is None:\n",
        "        logging.error(\"âŒ Error in processing patient data.\")\n",
        "        return\n",
        "\n",
        "    risk_score = calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence)\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "AUDIO_FILE_PATH = \"/content/f0108.wav\"\n",
        "ECG_IMAGE_PATH = \"/content/HB(3).jpg\"\n",
        "\n",
        "evaluate_patient(AUDIO_FILE_PATH, ECG_IMAGE_PATH)\n"
      ],
      "metadata": {
        "id": "AKLzDTnkUALN",
        "outputId": "71d47975-0f35-48e8-b943-a563344b24c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available ECG Class Labels: ['ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
            " 'ECG Images of Patient that have History of MI (172x12=2064)'\n",
            " 'ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
            " 'Normal Person ECG Images (284x12=3408)']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-13aa3e5e2c70>:87: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  confidence = float(prediction[0])  # Probability of being Unhealthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3322629512133972"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.4.1.post1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j10Iz9pshURO",
        "outputId": "d350c8c4-8272-4545-a220-915e554952c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.4.1.post1\n",
            "  Downloading scikit_learn-1.4.1.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.1.post1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.1.post1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.1.post1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.1.post1) (3.5.0)\n",
            "Downloading scikit_learn-1.4.1.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.4.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/new.xlsx\")\n",
        "print(df.head())  # Check the first few rows\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXtPn2OhrR1",
        "outputId": "ef9a5e62-ec58-4469-e352-5d6c69d7ce60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6  \\\n",
            "0  0.050481 -0.339781  0.265111  0.045092  0.040086  0.087173  0.092814   \n",
            "1 -0.019198 -0.012369  0.049249  0.042435  0.102515  0.086274 -0.179430   \n",
            "2  0.022934  0.006696  0.041837  0.071592  0.068073  0.091548  0.114399   \n",
            "3  0.017883  0.036710  0.004640  0.038210  0.085609  0.075911  0.116421   \n",
            "4 -0.050635 -0.254571  0.004206  0.064948  0.113252  0.093907  0.094563   \n",
            "\n",
            "          7         8         9  ...      1991      1992      1993      1994  \\\n",
            "0  0.099586 -0.143305  0.164186  ... -0.401426 -0.402333 -0.373426 -0.303710   \n",
            "1  0.182514  0.144317  0.163252  ... -0.378149 -0.162815 -0.295464 -0.106774   \n",
            "2  0.116452  0.178171  0.160357  ... -0.226982 -0.209063 -0.197806 -0.162262   \n",
            "3  0.148803  0.164897  0.167658  ... -0.212147 -0.197705 -0.179078 -0.181514   \n",
            "4  0.140718  0.160440  0.139388  ... -0.424251 -0.377917 -0.341359 -0.306715   \n",
            "\n",
            "       1995      1996      1997      1998      1999   Label  \n",
            "0  0.008599 -0.180633 -0.143135 -0.084758  0.060668      MI  \n",
            "1 -0.216412 -0.197570 -0.146570 -0.067230  0.005423      MI  \n",
            "2 -0.136338 -0.093322 -0.075758 -0.026654 -0.002047      MI  \n",
            "3 -0.118804 -0.112509 -0.042181 -0.023315  0.023233      MI  \n",
            "4 -0.223379 -0.191101 -0.149774 -0.058673 -0.052832  Normal  \n",
            "\n",
            "[5 rows x 2001 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsNgcrSspH-q",
        "outputId": "6bbfba2c-f189-442d-b385-e64ed17d6ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.1.post1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.4.1.post1\n",
            "    Uninstalling scikit-learn-1.4.1.post1:\n",
            "      Successfully uninstalled scikit-learn-1.4.1.post1\n",
            "Successfully installed scikit-learn-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models (Suppressing Compilation Warning)\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/ppg_scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder Safely\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixing 'Label' KeyError)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove non-numeric column\n",
        "    else:\n",
        "        print(\"Warning: 'Label' column not found in PPG data. Proceeding without it.\")\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # Load PPG Data Safely\n",
        "    try:\n",
        "        df_ppg = pd.read_excel(ppg_file)  # Read .xlsx instead of .csv\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})  # Convert 'MI' to 1 and 'Normal' to 0\n",
        "        else:\n",
        "            print(\"Warning: 'Label' column not found in PPG data.\")\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take the first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/f0108.wav\", \"/content/HB(3).jpg\", \"/content/new_fixed_corrected.xlsx\")\n"
      ],
      "metadata": {
        "id": "OpnXf9wcHFja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18311de-5e9a-4408-aacc-b509dd72a0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'Label' column not found in PPG data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Warning: 'Label' column not found in PPG data. Proceeding without it.\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Patient that have abnormal heartbeat (233x12=2796) (Confidence: 0.94)\n",
            "PPG Result: Myocardial Infarction (Confidence: 1.00)\n",
            "Final Risk Score: 0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-19-e76756006459>:124: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-19-e76756006459>:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5200154614279883"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The risk score is calculated using the formula:\n",
        "\n",
        "FinalÂ RiskÂ Score\n",
        "=\n",
        "AudioÂ Risk\n",
        "+\n",
        "ECGÂ Risk\n",
        "+\n",
        "PPGÂ Risk\n",
        "3\n",
        "FinalÂ RiskÂ Score=\n",
        "3\n",
        "AudioÂ Risk+ECGÂ Risk+PPGÂ Risk\n",
        "â€‹\n",
        "\n",
        "where:\n",
        "\n",
        "Audio Risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "ECG Risk = ECG_RISK_WEIGHTS[ecg_result] * ecg_confidence\n",
        "PPG Risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "Given:\n",
        "ECG Result = Normal\n",
        "\n",
        "ECG_RISK_WEIGHTS[\"Normal Person ECG Images (284x12=3408)\"] = 0.1\n",
        "ECG Confidence: Let's assume 0.9 (Example)\n",
        "ECG Risk =\n",
        "0.1\n",
        "Ã—\n",
        "0.9\n",
        "=\n",
        "0.09\n",
        "0.1Ã—0.9=0.09\n",
        "Heart Sound Result = Unhealthy\n",
        "\n",
        "AUDIO_RISK_WEIGHTS[\"Unhealthy\"] = 0.9\n",
        "Audio Confidence: Let's assume 0.8 (Example)\n",
        "Audio Risk =\n",
        "0.9\n",
        "Ã—\n",
        "0.8\n",
        "=\n",
        "0.72\n",
        "0.9Ã—0.8=0.72\n",
        "PPG Result = Myocardial Infarction (MI)\n",
        "\n",
        "PPG_RISK_WEIGHTS[1] = 0.9\n",
        "PPG Confidence: Let's assume 0.85 (Example)\n",
        "PPG Risk =\n",
        "0.9\n",
        "Ã—\n",
        "0.85\n",
        "=\n",
        "0.765\n",
        "0.9Ã—0.85=0.765\n",
        "Final Risk Score Calculation:\n",
        "FinalÂ RiskÂ Score\n",
        "=\n",
        "0.72\n",
        "+\n",
        "0.09\n",
        "+\n",
        "0.765\n",
        "3\n",
        "FinalÂ RiskÂ Score=\n",
        "3\n",
        "0.72+0.09+0.765\n",
        "â€‹\n",
        "\n",
        "=\n",
        "1.575\n",
        "3\n",
        "=\n",
        "0.525\n",
        "=\n",
        "3\n",
        "1.575\n",
        "â€‹\n",
        " =0.525\n",
        "Final Risk Score = 0.53 (Rounded to Two Decimal Places)\n",
        "This means the overall heart disease risk is moderate (52.5%), influenced mostly by the Unhealthy Heart Sound and PPG MI prediction, while the Normal ECG lowers the overall risk.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You said:\n",
        "FROM WHERE DID YOU GET THOSE CONFIDENCE\n",
        "ChatGPT said:\n",
        "The confidence values for each prediction come from the model outputs. In your code, each model predicts a probability or confidence score. Let's break it down:\n",
        "\n",
        "1. Audio Confidence\n",
        "In the function detect_heart_disease(audio_path), the heart sound model predicts a probability:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "prediction = audio_model.predict(features)[0]  # Returns probability between 0 and 1\n",
        "predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "If the model predicts 0.8, and the result is Unhealthy, then:\n",
        "Audio Confidence = 0.8\n",
        "2. ECG Confidence\n",
        "In predict_disease(ecg_path), the ECG model predicts probabilities for multiple classes. The highest probability is taken:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "prediction = ecg_model.predict(final_features)  # Returns array of probabilities\n",
        "predicted_class_index = np.argmax(prediction)  # Get index of max probability\n",
        "predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "confidence = float(np.max(prediction))  # Take highest probability as confidence\n",
        "If the Normal ECG class has the highest probability 0.9, then:\n",
        "ECG Confidence = 0.9\n",
        "3. PPG Confidence\n",
        "In predict_ppg(ppg_row), the model gives a probability for Myocardial Infarction (MI):\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]  # Probability of MI\n",
        "predicted_class = 1 if prediction_prob > 0.5 else 0  # 1 = MI, 0 = Normal\n",
        "If the model predicts 0.85 for MI, then:\n",
        "PPG Confidence = 0.85\n",
        "Summary of Confidence Values\n",
        "Audio Confidence = 0.8 (from heart sound model)\n",
        "ECG Confidence = 0.9 (from ECG model)\n",
        "PPG Confidence = 0.85 (from PPG model)\n",
        "These confidence scores are used in the risk score calculation:\n",
        "\n",
        "FinalÂ RiskÂ Score\n",
        "=\n",
        "(\n",
        "0.9\n",
        "Ã—\n",
        "0.8\n",
        ")\n",
        "+\n",
        "(\n",
        "0.1\n",
        "Ã—\n",
        "0.9\n",
        ")\n",
        "+\n",
        "(\n",
        "0.9\n",
        "Ã—\n",
        "0.85\n",
        ")\n",
        "3\n",
        "FinalÂ RiskÂ Score=\n",
        "3\n",
        "(0.9Ã—0.8)+(0.1Ã—0.9)+(0.9Ã—0.85)\n",
        "â€‹\n",
        "\n",
        "=\n",
        "0.72\n",
        "+\n",
        "0.09\n",
        "+\n",
        "0.765\n",
        "3\n",
        "=\n",
        "0.525\n",
        "=\n",
        "3\n",
        "0.72+0.09+0.765\n",
        "â€‹\n",
        " =0.525\n",
        "So, the risk score is 0.53 (or 53%), meaning a moderate risk of heart disease."
      ],
      "metadata": {
        "id": "ct-iKMAfsHEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models (Suppressing Compilation Warning)\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/ppg_scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder Safely\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixing 'Label' KeyError)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove non-numeric column\n",
        "    else:\n",
        "        print(\"Warning: 'Label' column not found in PPG data. Proceeding without it.\")\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # Load PPG Data Safely\n",
        "    try:\n",
        "        df_ppg = pd.read_excel(ppg_file)  # Read .xlsx instead of .csv\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})  # Convert 'MI' to 1 and 'Normal' to 0\n",
        "        else:\n",
        "            print(\"Warning: 'Label' column not found in PPG data.\")\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take the first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/UNHEALTHYSOUND.wav\", \"/content/Normal(3).jpg\", \"/content/new_fixed_corrected.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1Y7YQc9q3MR",
        "outputId": "59f6efdb-f7fe-454c-93a9-1b7b776b3ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'Label' column not found in PPG data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Warning: 'Label' column not found in PPG data. Proceeding without it.\n",
            "Audio Result: Unhealthy (Confidence: 1.00)\n",
            "ECG Result: Normal Person ECG Images (284x12=3408) (Confidence: 0.91)\n",
            "PPG Result: Myocardial Infarction (Confidence: 1.00)\n",
            "Final Risk Score: 0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-20-4361906b9905>:124: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-20-4361906b9905>:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6284172069857734"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models (Suppressing Compilation Warning)\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/ppg_scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder Safely\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixing 'Label' KeyError)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove non-numeric column\n",
        "    else:\n",
        "        print(\"Warning: 'Label' column not found in PPG data. Proceeding without it.\")\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # Load PPG Data Safely\n",
        "    try:\n",
        "        df_ppg = pd.read_excel(ppg_file)  # Read .xlsx instead of .csv\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})  # Convert 'MI' to 1 and 'Normal' to 0\n",
        "        else:\n",
        "            print(\"Warning: 'Label' column not found in PPG data.\")\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take the first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/UNHEALTHYSOUND.wav\", \"/content/MI(9).jpg\", \"/content/new_fixed_corrected.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX8RfVwp_qY1",
        "outputId": "c89c3120-0449-4639-ad43-c16564768a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Warning: 'Label' column not found in PPG data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Warning: 'Label' column not found in PPG data. Proceeding without it.\n",
            "Audio Result: Unhealthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Myocardial Infarction Patients (240x12=2880) (Confidence: 0.97)\n",
            "PPG Result: Myocardial Infarction (Confidence: 1.00)\n",
            "Final Risk Score: 0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-2-699ea71b3854>:124: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-2-699ea71b3854>:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8903404664824622"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit opencv-python-headless joblib librosa tensorflow ngrok pandas xlrd\n"
      ],
      "metadata": {
        "id": "9PVb2NImwY_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models (Suppressing Compilation Warning)\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder Safely\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixing 'Label' KeyError)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove non-numeric column\n",
        "    else:\n",
        "        print(\"Warning: 'Label' column not found in PPG data. Proceeding without it.\")\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # Load PPG Data Safely\n",
        "    try:\n",
        "        df_ppg = pd.read_excel(ppg_file)  # Read .xlsx instead of .csv\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})  # Convert 'MI' to 1 and 'Normal' to 0\n",
        "        else:\n",
        "            print(\"Warning: 'Label' column not found in PPG data.\")\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take the first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0011.wav\", \"/content/Normal(13).jpg\", \"/content/Normal.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haiw59DSwMex",
        "outputId": "5cd17e34-56bc-4482-c8ee-9a0d73a0e713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading PPG data: Excel file format cannot be determined, you must specify an engine manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0011.wav\", \"/content/Normal(13).jpg\", \"/content/Normal.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kurWuPVq0BqV",
        "outputId": "489582c4-2c80-43e6-9707-3b0d43a66e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cf03090ad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cf03090a8e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: Normal Person ECG Images (284x12=3408) (Confidence: 0.87)\n",
            "PPG Result: Normal (Confidence: 0.02)\n",
            "Final Risk Score: 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-8-a28f2e9338df>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-8-a28f2e9338df>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0630960969362568"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ooPOZcMl06LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0011.wav\", \"/content/Normal(13).jpg\", \"/content/MI.csv\")\n"
      ],
      "metadata": {
        "id": "BMFwITqMHubD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66164c5-a17f-4171-b7bd-e30cbfa0b32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: Normal Person ECG Images (284x12=3408) (Confidence: 0.87)\n",
            "PPG Result: Myocardial Infarction (Confidence: 0.99)\n",
            "Final Risk Score: 0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-9-dd48b032544d>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-9-dd48b032544d>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36002896809439977"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/e00670.wav\", \"/content/Normal(13).jpg\", \"/content/MI.csv\")\n"
      ],
      "metadata": {
        "id": "hEVw3hPH4L3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1188bafc-3825-4198-f385-3bd27cd80c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Audio Result: Unhealthy (Confidence: 1.00)\n",
            "ECG Result: Normal Person ECG Images (284x12=3408) (Confidence: 0.87)\n",
            "PPG Result: Myocardial Infarction (Confidence: 0.99)\n",
            "Final Risk Score: 0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-14-be0576f2a2e4>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-14-be0576f2a2e4>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6262791870421283"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0016.wav\", \"/content/MI.jpg\", \"/content/Normal.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxDOqKx01G_y",
        "outputId": "8a7df5b8-b674-49cd-d7b2-61d5a15b52af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Patient that have abnormal heartbeat (233x12=2796) (Confidence: 1.00)\n",
            "PPG Result: Normal (Confidence: 0.02)\n",
            "Final Risk Score: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-1-c54ff7dfb899>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-1-c54ff7dfb899>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23407972139456978"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0016.wav\", \"/content/mi_2.jpg\", \"/content/Normal.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO1SfmOI3vPj",
        "outputId": "ae9148e2-459c-4e6c-a4dc-7eb2b6d6b410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3f4c0045e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3f4c005620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Patient that have abnormal heartbeat (233x12=2796) (Confidence: 0.52)\n",
            "PPG Result: Normal (Confidence: 0.02)\n",
            "Final Risk Score: 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-2-b80a1d0c7bb2>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-2-b80a1d0c7bb2>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13817559761145823"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/a0016.wav\", \"/content/infmi_2x.jpg\", \"/content/Normal.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSX_VnsH4c61",
        "outputId": "e9601362-2cb7-4855-d1cf-970195178550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Audio Result: Healthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Patient that have abnormal heartbeat (233x12=2796) (Confidence: 1.00)\n",
            "PPG Result: Normal (Confidence: 0.02)\n",
            "Final Risk Score: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-3-8a2a8c2b5ea6>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-3-8a2a8c2b5ea6>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23407972139456978"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pickle\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# âœ… Load Models\n",
        "AUDIO_MODEL_PATH = \"/content/SOUND_LSTM_model.h5\"\n",
        "ECG_MODEL_PATH = \"/content/Resnet+EffieciencyNet+MLP_ecg_model (2).h5\"\n",
        "ENCODER_PATH = \"/content/label_encoder.pkl\"\n",
        "PPG_MODEL_PATH = \"/content/best_ppg_model.pkl\"\n",
        "SCALER_PATH = \"/content/scaler.pkl\"\n",
        "\n",
        "audio_model = load_model(AUDIO_MODEL_PATH, compile=False)\n",
        "ecg_model = load_model(ECG_MODEL_PATH, compile=False)\n",
        "ppg_model = joblib.load(PPG_MODEL_PATH)\n",
        "scaler = joblib.load(SCALER_PATH)\n",
        "\n",
        "# âœ… Load Label Encoder\n",
        "try:\n",
        "    with open(ENCODER_PATH, \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "except Exception as e:\n",
        "    print(\"Error loading LabelEncoder:\", e)\n",
        "    label_encoder = None\n",
        "\n",
        "# âœ… Load Feature Extractors\n",
        "base_model1 = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "base_model2 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# âœ… Risk Weights\n",
        "ECG_RISK_WEIGHTS = {\n",
        "    \"ECG Images of Myocardial Infarction Patients (240x12=2880)\": 0.9,\n",
        "    \"ECG Images of Patient that have History of MI (172x12=2064)\": 0.7,\n",
        "    \"ECG Images of Patient that have abnormal heartbeat (233x12=2796)\": 0.6,\n",
        "    \"Normal Person ECG Images (284x12=3408)\": 0.1\n",
        "}\n",
        "AUDIO_RISK_WEIGHTS = {\"Healthy\": 0.1, \"Unhealthy\": 0.9}\n",
        "PPG_RISK_WEIGHTS = {0: 0.1, 1: 0.9}  # 0 = Normal, 1 = Myocardial Infarction\n",
        "\n",
        "# âœ… Audio Preprocessing\n",
        "def preprocess_audio(file_path, max_pad_len=400):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=2000)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
        "    return mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
        "\n",
        "# âœ… ECG Preprocessing\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return preprocess_input(img)\n",
        "\n",
        "# âœ… PPG Preprocessing (Fixed Feature Mismatch)\n",
        "def preprocess_ppg(data_row):\n",
        "    if \"Label\" in data_row:\n",
        "        data_row = data_row.drop(columns=[\"Label\"])  # Remove target column\n",
        "\n",
        "    # âœ… Ensure only 2000 features\n",
        "    if len(data_row) > 2000:\n",
        "        data_row = data_row.iloc[:2000]  # Trim extra features\n",
        "\n",
        "    data_row_scaled = scaler.transform([data_row])\n",
        "    return data_row_scaled\n",
        "\n",
        "# âœ… Predictions\n",
        "def detect_heart_disease(audio_path):\n",
        "    features = preprocess_audio(audio_path)\n",
        "    prediction = audio_model.predict(features)[0]\n",
        "    predicted_class = \"Unhealthy\" if prediction > 0.5 else \"Healthy\"\n",
        "    confidence = prediction if predicted_class == \"Unhealthy\" else 1 - prediction\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def predict_disease(ecg_path):\n",
        "    img = preprocess_image(ecg_path)\n",
        "    eff_features = base_model1.predict(img)\n",
        "    res_features = base_model2.predict(img)\n",
        "    final_features = np.hstack((eff_features, res_features))\n",
        "    prediction = ecg_model.predict(final_features)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    else:\n",
        "        predicted_class = f\"Class_{predicted_class_index}\"  # Fallback label\n",
        "\n",
        "    return predicted_class, float(np.max(prediction))\n",
        "\n",
        "def predict_ppg(ppg_row):\n",
        "    processed_ppg = preprocess_ppg(ppg_row)\n",
        "    prediction_prob = ppg_model.predict_proba(processed_ppg)[:, 1][0]\n",
        "    predicted_class = 1 if prediction_prob > 0.5 else 0\n",
        "    return predicted_class, prediction_prob\n",
        "\n",
        "# âœ… Risk Calculation\n",
        "def calculate_risk(audio_result, audio_confidence, ecg_result, ecg_confidence, ppg_result, ppg_confidence):\n",
        "    audio_risk = AUDIO_RISK_WEIGHTS[audio_result] * audio_confidence\n",
        "    ecg_risk = ECG_RISK_WEIGHTS.get(ecg_result, 0) * ecg_confidence\n",
        "    ppg_risk = PPG_RISK_WEIGHTS[ppg_result] * ppg_confidence\n",
        "    final_risk_score = (audio_risk + ecg_risk + ppg_risk) / 3\n",
        "    return final_risk_score\n",
        "\n",
        "def evaluate_patient(audio_path, ecg_path, ppg_file):\n",
        "    # âœ… Load PPG Data\n",
        "    try:\n",
        "        df_ppg = pd.read_csv(ppg_file)\n",
        "\n",
        "        # âœ… Fix 'Label' column if exists\n",
        "        if \"Label\" in df_ppg.columns:\n",
        "            df_ppg[\"Label\"] = df_ppg[\"Label\"].map({\"Normal\": 0, \"MI\": 1})\n",
        "\n",
        "        ppg_row = df_ppg.dropna().iloc[0]  # Take first valid row\n",
        "    except Exception as e:\n",
        "        print(\"Error loading PPG data:\", e)\n",
        "        return None\n",
        "\n",
        "    audio_result, audio_confidence = detect_heart_disease(audio_path)\n",
        "    ecg_result, ecg_confidence = predict_disease(ecg_path)\n",
        "    ppg_result, ppg_confidence = predict_ppg(ppg_row)\n",
        "    risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
        "\n",
        "    # âœ… Convert NumPy values to float for proper formatting\n",
        "    print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n",
        "    print(f\"ECG Result: {ecg_result} (Confidence: {float(ecg_confidence):.2f})\")\n",
        "    print(f\"PPG Result: {'Myocardial Infarction' if ppg_result == 1 else 'Normal'} (Confidence: {float(ppg_confidence):.2f})\")\n",
        "    print(f\"Final Risk Score: {risk_score:.2f}\")\n",
        "\n",
        "    return risk_score\n",
        "\n",
        "# âœ… Example Usage\n",
        "evaluate_patient(\"/content/e00603.wav\", \"/content/MI(240).jpg\", \"/content/MI.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYqlVXNU4pHH",
        "outputId": "96fb54f3-b3c8-4f5d-872a-1243888b879a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Audio Result: Unhealthy (Confidence: 1.00)\n",
            "ECG Result: ECG Images of Myocardial Infarction Patients (240x12=2880) (Confidence: 0.79)\n",
            "PPG Result: Myocardial Infarction (Confidence: 0.99)\n",
            "Final Risk Score: 0.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-7-fd153e2767a5>:128: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  risk_score = calculate_risk(audio_result, float(audio_confidence), ecg_result, float(ecg_confidence), ppg_result, float(ppg_confidence))\n",
            "<ipython-input-7-fd153e2767a5>:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Audio Result: {audio_result} (Confidence: {float(audio_confidence):.2f})\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83416817966959"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}